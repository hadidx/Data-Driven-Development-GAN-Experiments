{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not run unless tensorflow can't find cuda\n",
    "import os\n",
    "os.environ['CUDA_DIR'] = \"/usr/lib/cuda\"\n",
    "os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/lib/cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 00:09:27.615466: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-05 00:09:27.638006: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 00:09:27.638023: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 00:09:27.638915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-05 00:09:27.644172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 00:09:28.031370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Load the VAE-GANs for healthy and fractured vertebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(128, 128, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=16*16*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(16, 16, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=128, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "\n",
    "  def generate(self, mean, logvar):\n",
    "    z = self.reparameterize(mean, logvar)\n",
    "    x_logit = self.decode(z, apply_sigmoid=True)\n",
    "    return x_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 00:09:28.552092: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.580987: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.581131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.582719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.582816: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.582897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.630980: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.631097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.631192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-05 00:09:28.631272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22222 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x719964038fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "generator_healthy = CVAE(latent_dim)\n",
    "generator_healthy.load_weights('./real_healthy_cts_transfer_variational_autoencoder_generator')\n",
    "\n",
    "latent_dim = 100\n",
    "generator_fractured = CVAE(latent_dim)\n",
    "generator_fractured.load_weights('./real_fractured_cts_transfer_variational_autoencoder_generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the images and their categories into memory. Save the images in the images[] array and the categories in the categories[] array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "h15-brv7H8W4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "path = '../cropped_healthy_vertebra'\n",
    "\n",
    "categories = []\n",
    "images = []\n",
    "\n",
    "for image_file in os.listdir(path):\n",
    "            img = cv2.imread(osp.join(path, image_file))\n",
    "            hh, ww = img.shape[:2]\n",
    "            maximum = max(hh, ww)\n",
    "            img = cv2.resize(img,(128,128))\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "            categories.append('healthy')\n",
    "        \n",
    "path = '../cropped_fractured_vertebra'\n",
    "for image_file in os.listdir(path):\n",
    "            img = cv2.imread(osp.join(path, image_file))\n",
    "            hh, ww = img.shape[:2]\n",
    "            maximum = max(hh, ww)\n",
    "            \n",
    "            img = cv2.resize(img,(128,128))\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "            categories.append('fractured')        \n",
    "\n",
    "images = np.array(images)\n",
    "categories = np.array(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqDUuTVzn-nn"
   },
   "source": [
    "2. Convert the images into numpy arrays, and perform one hot encoding on the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images\n",
    "y = categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cmD73y4oUTM"
   },
   "source": [
    "4. Split the data between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x4o-w0aKCRS6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y , test_size = 0.2,stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(X_train)\n",
    "y_train = list(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Generate N healthy CTs and N fractured CTs. For the case of no augmentation, N is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]2024-05-05 00:09:37.880467: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "100%|██████████| 25000/25000 [01:05<00:00, 382.99it/s]\n",
      "100%|██████████| 25000/25000 [01:05<00:00, 379.92it/s]\n"
     ]
    }
   ],
   "source": [
    "N = 25000\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(N)):\n",
    "            noise_mean = tf.random.normal([1, latent_dim])\n",
    "            noise_logvar = tf.random.normal([1, latent_dim])\n",
    "            \n",
    "            generated_image = generator_healthy.generate(noise_mean, noise_logvar)\n",
    "            X_train.append(np.reshape(generated_image, (128,128)))\n",
    "            y_train.append('healthy')\n",
    "            \n",
    "for i in tqdm(range(N)):\n",
    "            noise_mean = tf.random.normal([1, latent_dim])\n",
    "            noise_logvar = tf.random.normal([1, latent_dim])\n",
    "            generated_image = generator_fractured.generate(noise_mean, noise_logvar)\n",
    "            X_train.append(np.reshape(generated_image, (128,128)))\n",
    "            y_train.append('fractured') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iv2J66DE-CRR",
    "outputId": "76ddf41d-8b5a-4f0a-fa48-c5fa4c2397ed"
   },
   "outputs": [],
   "source": [
    "# X_train = (X_train) / 255\n",
    "# X_test = (X_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(pd.DataFrame(y_train))\n",
    "y_test = pd.get_dummies(pd.DataFrame(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50523, 128, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKSrcK23OrI9"
   },
   "source": [
    "6. Build an initial neural network and print its architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ar3lam-WboRm",
    "outputId": "6b315da1-4c1e-43f6-ef02-f390193dff3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 57600)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               7372928   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7392002 (28.20 MB)\n",
      "Trainable params: 7392002 (28.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, activation='relu', input_shape=(128,128,1)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHXGchyNPA1j"
   },
   "source": [
    "7. Compile and train the initial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJIexgxqGGdN",
    "outputId": "be991607-54ba-41c5-d598-3f0365a48e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 00:11:53.344417: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-05-05 00:11:53.926698: I external/local_xla/xla/service/service.cc:168] XLA service 0x7197a8838240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-05 00:11:53.926715: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-05-05 00:11:53.929786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714857113.980865  939010 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579/1579 [==============================] - 7s 3ms/step - loss: 0.3063 - accuracy: 0.8634 - val_loss: 0.3768 - val_accuracy: 0.8626\n",
      "Epoch 2/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.1306 - accuracy: 0.9493 - val_loss: 0.4514 - val_accuracy: 0.8702\n",
      "Epoch 3/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9684 - val_loss: 0.3873 - val_accuracy: 0.8779\n",
      "Epoch 4/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0636 - accuracy: 0.9764 - val_loss: 0.5041 - val_accuracy: 0.8855\n",
      "Epoch 5/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 0.5162 - val_accuracy: 0.8855\n",
      "Epoch 6/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0431 - accuracy: 0.9841 - val_loss: 0.5701 - val_accuracy: 0.9008\n",
      "Epoch 7/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0361 - accuracy: 0.9863 - val_loss: 0.6521 - val_accuracy: 0.8855\n",
      "Epoch 8/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.6424 - val_accuracy: 0.8779\n",
      "Epoch 9/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0289 - accuracy: 0.9895 - val_loss: 0.7068 - val_accuracy: 0.8626\n",
      "Epoch 10/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0276 - accuracy: 0.9904 - val_loss: 0.6081 - val_accuracy: 0.8855\n",
      "Epoch 11/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.7257 - val_accuracy: 0.9008\n",
      "Epoch 12/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.9304 - val_accuracy: 0.8779\n",
      "Epoch 13/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.6768 - val_accuracy: 0.8855\n",
      "Epoch 14/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.9223 - val_accuracy: 0.8779\n",
      "Epoch 15/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.9791 - val_accuracy: 0.8779\n",
      "Epoch 16/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 1.0031 - val_accuracy: 0.8779\n",
      "Epoch 17/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 1.1100 - val_accuracy: 0.8626\n",
      "Epoch 18/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.8679 - val_accuracy: 0.8931\n",
      "Epoch 19/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.8779 - val_accuracy: 0.9084\n",
      "Epoch 20/20\n",
      "1579/1579 [==============================] - 5s 3ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.9357 - val_accuracy: 0.8855\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe0Sx7p_PYJm"
   },
   "source": [
    "8. Calculate the classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoFt7EmasArp",
    "outputId": "54da9eac-5f44-48d9-9cdb-46e0659b32a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.85      0.89      0.87        56\n",
      "   Fractured       0.92      0.88      0.90        75\n",
      "\n",
      "    accuracy                           0.89       131\n",
      "   macro avg       0.88      0.89      0.88       131\n",
      "weighted avg       0.89      0.89      0.89       131\n",
      "\n",
      "The accuracy is 0.8854961832061069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = np.argmax(np.array(y_test), axis=1)\n",
    "\n",
    "y_predicted = np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "target_names = ['Healthy','Fractured']\n",
    "\n",
    "print(classification_report(y_true, y_predicted, target_names=target_names))\n",
    "print('The accuracy is',accuracy_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_benign</th>\n",
       "      <th>0_malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0_benign  0_malignant\n",
       "2           1            0\n",
       "396         0            1\n",
       "440         0            1\n",
       "142         1            0\n",
       "29          1            0\n",
       "..        ...          ...\n",
       "379         0            1\n",
       "458         0            1\n",
       "90          1            0\n",
       "325         0            1\n",
       "226         1            0\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
